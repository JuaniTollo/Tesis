Empresa,Dataset,Modelo,Base/Fine-tuning,Capas LoRa,Tama침o batch,Learning rate,Iters,Adapter,Lora_Rank,Accuracy Entrenamiento,Accuracy Validaci칩n,Accuracy Test,EC Entrenamiento,EC Validaci칩n,EC Testeo,ECN Entrenamiento,ECN Validaci칩n,ECN Testeo
Microsoft,hellaswag,phi 2,Fine-tuning,16,5,1.0e-05,5,Best,chose,0.73,0.7233333333333334,0.6533333333333333,0.7371460199356079,0.7111406922340393,0.8591530323028564,0.06798049194620301,0.06558224936933976,0.07923212526891503
Microsoft,hellaswag,phi 2,Fine-tuning,16,5,1.0e-05,5,Best,adapter,0.73,0.7233333333333334,0.6533333333333333,0.7371460199356079,0.7111406922340393,0.8591530323028564,0.06798049194620301,0.06558224936933976,0.07923212526891503
Microsoft,hellaswag,phi 2,Fine-tuning,16,5,1.0e-05,5,Best,chose,0.73,0.7233333333333334,0.6533333333333333,0.7371460199356079,0.7111406922340393,0.8591530323028564,0.06798049194620301,0.06558224936933976,0.07923212526891503
Microsoft,hellaswag,phi 2,Fine-tuning,16,5,1.0e-05,5,Best,chose,0.73,0.7233333333333334,0.6533333333333333,0.7371460199356079,0.7111406922340393,0.8591530323028564,0.06798049194620301,0.06558224936933976,0.07923212526891503
